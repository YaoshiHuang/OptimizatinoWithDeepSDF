{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PATH=/usr/local/cuda/bin:$PATH\n",
    "!export CPATH=/usr/local/cuda/include:$CPATH\n",
    "!export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\n",
    "!pip install --user torch==1.4.0+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install --user torch-scatter==latest+cu100 torch-sparse==latest+cu100 -f https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.4.0.html\n",
    "!pip install --user torch-cluster==1.5.4+cu100 torch-spline-conv==1.1.1 torch-geometric==1.4.2 -f https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.4.0.html\n",
    "!pip install --user ipympl pyntcloud\n",
    "\n",
    "# !curl -sL https://deb.nodesource.com/setup_13.x | sudo -E bash -\n",
    "# !sudo apt-get install -y nodejs\n",
    "\n",
    "# !pip install  --user ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# !sudo jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "\n",
    "# Warning! Sometimes you have to use --no-cache-dir to avoid undefined symbol error\n",
    "\n",
    "# Matplotlib\n",
    "# !pip install â€”user ipympl\n",
    "\n",
    "# !jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "# !jupyter labextension install jupyter-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insrtall openfoam\n",
    "!sudo apt-get install -y openssh-client\n",
    "!sudo apt-get install -y software-properties-common\n",
    "!sudo sh -c \"wget -O - https://dl.openfoam.org/gpg.key | apt-key add -\"\n",
    "!sudo add-apt-repository http://dl.openfoam.org/ubuntu\n",
    "!sudo apt-get update\n",
    "!sudo apt-get -y install openfoam5\n",
    "\n",
    "!pip install --user numpy-stl\n",
    "!echo \"export PATH=/cvlabdata2/home/artem/autofoam/bin:$PATH\" >> ~/.bashrc \n",
    "!echo \". /opt/openfoam5/etc/bashrc\" >> ~/.bashrc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt update\n",
    "!sudo wget https://github.com/mmatl/travis_debs/raw/master/xenial/mesa_18.3.3-0.deb\n",
    "!sudo dpkg -i ./mesa_18.3.3-0.deb || true\n",
    "!sudo apt install -f\n",
    "!git clone https://github.com/mmatl/pyopengl.git\n",
    "!pip install --user ./pyopengl\n",
    "\n",
    "!pip install --user pyrender\n",
    "!pip3 install --user mesh-to-sdf\n",
    "!export PYOPENGL_PLATFORM=osmesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import (NNConv, GMMConv, GraphConv, Set2Set)\n",
    "from torch_geometric.nn import (SplineConv, graclus, max_pool, max_pool_x, global_mean_pool)\n",
    "\n",
    "#from neuralnet_pytorch.metrics import chamfer_loss\n",
    "\n",
    "import trimesh\n",
    "\n",
    "from visualization_utils import plot_mesh_3d\n",
    "\n",
    "from models import *\n",
    "from datasets import compute_lift, CDFDataset, CDFDatasetInMemory, compute_lift_faces, make_data_instance_from_stl\n",
    "from visualization_utils import saveMeshPly\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = trimesh.load('Expirements/OptimizationPaper/DeepSDFDrag/meshes/00025.ply')\\\n",
    "           .export('Expirements/Simulations/RawSimulations/inputs/mesh3DeepSDF25conservative_input.stl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Statistics for Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk('/cvlabdata2/home/artem/Data/cars_refined/simulated/fld'):\n",
    "    objects += [os.path.join(dirpath, file) for file in filenames if file[-4:] == '.fld']\n",
    "\n",
    "mean_values = np.zeros((len(objects), 4))\n",
    "std_values = np.zeros((len(objects), 4))\n",
    "\n",
    "for idx, fld_path in tqdm(enumerate(objects), total=len(objects)):\n",
    "    fld = np.genfromtxt(fld_path, delimiter=',', skip_header=1)\n",
    "    fld[fld > 10e5] = np.nan\n",
    "    fld = fld[~np.isnan(fld).any(axis=1)]\n",
    "\n",
    "    answers = fld[:, 3:]\n",
    "\n",
    "    for f in range(answers.shape[1]):\n",
    "        mean_values[idx, f] = np.mean(answers[:, f])\n",
    "        std_values[idx, f] = np.std(answers[:, f])\n",
    "        \n",
    "print(np.mean(mean_values, axis=0))\n",
    "print(np.mean(std_values, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk('/cvlabdata2/home/artem/Data/cars_refined/simulated/scr'):\n",
    "    objects += [os.path.join(dirpath, file) for file in filenames if file[-5:] == '.json' and file[0] != '.']\n",
    "\n",
    "scr_data_store = np.zeros((len(objects), 12))\n",
    "\n",
    "for idx, scr_path in tqdm(enumerate(objects), total=len(objects)):\n",
    "    with open(scr_path) as scr_file:\n",
    "        scr_data = json.load(scr_file)\n",
    "        scr_data_store[idx, :3] = scr_data['pressure_drag']\n",
    "        scr_data_store[idx, 3:6] = scr_data['viscous_drag']\n",
    "        scr_data_store[idx, 6:9] = scr_data['pressure_moment']\n",
    "        scr_data_store[idx, 9:] = scr_data['viscous_moment']  \n",
    "        \n",
    "print(np.mean(scr_data_store, axis=0))\n",
    "print(np.std(scr_data_store, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse the prediction of a trained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getR2Score(y, pred):\n",
    "    mean_data = np.mean(y.numpy())\n",
    "    sstot = np.sum((y.numpy() - mean_data) ** 2)\n",
    "    ssreg = np.sum((pred.numpy() - mean_data) ** 2)\n",
    "    ssres = np.sum((pred.numpy() - y.numpy()) ** 2)\n",
    "    return 1 - ssres / sstot\n",
    "\n",
    "def getModelReport(model, data_path=\"/cvlabdata2/home/artem/Data/cars_refined/simulated\", \n",
    "                   data_step=1, global_features=False):\n",
    "    val_dataset = CDFDatasetInMemory(data_path, train=False)\n",
    "    val_loader = torch_geometric.data.DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    \n",
    "    device = \"cuda:0\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    r2_scores = []\n",
    "    pathes = []\n",
    "    mses = []\n",
    "    verticies = []\n",
    "    for batch in tqdm(val_loader):\n",
    "        batch = batch.to(device)\n",
    "        if global_features:\n",
    "            local_preds, global_preds = model(batch.clone())\n",
    "        else:\n",
    "            local_preds = model(batch.clone())\n",
    "    \n",
    "        local_preds = local_preds.cpu().detach()\n",
    "        data_instance = batch.y.cpu().detach()\n",
    "            \n",
    "        r2_scores.append([getR2Score(data_instance[:, 0], local_preds[:, 0]),\n",
    "                          getR2Score(data_instance[:, 1], local_preds[:, 1]),\n",
    "                          getR2Score(data_instance[:, 2], local_preds[:, 2]),\n",
    "                          getR2Score(data_instance[:, 3], local_preds[:, 3]),\n",
    "                          getR2Score(data_instance, local_preds)])\n",
    "                         \n",
    "        mses.append([F.mse_loss(local_preds[:, 0], data_instance[:, 0]).numpy(),\n",
    "                     F.mse_loss(local_preds[:, 1], data_instance[:, 1]).numpy(),\n",
    "                     F.mse_loss(local_preds[:, 2], data_instance[:, 2]).numpy(),\n",
    "                     F.mse_loss(local_preds[:, 3], data_instance[:, 3]).numpy(),\n",
    "                     F.mse_loss(local_preds, data_instance).numpy()])\n",
    "        pathes.append(batch.path)\n",
    "        verticies.append(data_instance.shape[0])\n",
    "        \n",
    "    r2_scores_ret, mses_ret = np.array(r2_scores), np.array(mses)   \n",
    "    r2_scores, mses = r2_scores_ret, mses_ret \n",
    "    #r2_scores, mses = r2_scores_ret[r2_scores_ret[:, 0] > 0 , :], mses_ret[r2_scores_ret[:, 0] > 0, :]   \n",
    "    \n",
    "    print(\"Average number of verticies : \", int(np.mean(verticies)) )\n",
    "    print(\"Number of Model Parameters  : \", sum(p.numel() for p in model.parameters()))\n",
    "    print()\n",
    "    print(\"                     |        MSE       |       R2    \")\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(\"Pressure             | %.4f +- %.4f | %.4f +- %.4f\" % \n",
    "          (np.mean(mses[:, 0]), np.std(mses[:, 0]), np.mean(r2_scores[:, 0]), np.std(r2_scores[:, 0]) ) )\n",
    "    print(\"Kinetic Energy       | %.4f +- %.4f | %.4f +- %.4f\" % \n",
    "          (np.mean(mses[:, 1]), np.std(mses[:, 1]), np.mean(r2_scores[:, 1]), np.std(r2_scores[:, 1]) ))\n",
    "    print(\"Omega                | %.4f +- %.4f | %.4f +- %.4f\" % \n",
    "          (np.mean(mses[:, 2]), np.std(mses[:, 2]), np.mean(r2_scores[:, 2]), np.std(r2_scores[:, 2]) ))\n",
    "    print(\"Turbulent Viscosity  | %.4f +- %.4f | %.4f +- %.4f\" % \n",
    "          (np.mean(mses[:, 3]), np.std(mses[:, 3]), np.mean(r2_scores[:, 3]), np.std(r2_scores[:, 3]) ))\n",
    "    print(\"Total                | %.4f +- %.4f | %.4f +- %.4f\" % \n",
    "          (np.mean(mses[:, 4]), np.std(mses[:, 4]), np.mean(r2_scores[:, 4]), np.std(r2_scores[:, 4]) ))\n",
    "    \n",
    "    return r2_scores_ret, mses_ret, pathes\n",
    "\n",
    "\n",
    "\n",
    "def getLiftModelReport(model, data_path=\"/cvlabdata2/home/artem/Data/cars_refined/simulated\", \n",
    "                       data_step=1, global_features=False):\n",
    "    val_dataset = CDFDatasetInMemory(data_path, connectivity=10, train=False, data_step=data_step)\n",
    "    val_loader = torch_geometric.data.DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    device = \"cuda:0\"\n",
    "    model = model.to(device)\n",
    "\n",
    "    predicted = []\n",
    "    correct = []\n",
    "    for batch in tqdm(val_loader):\n",
    "        batch = batch.to(device)\n",
    "        if global_features:\n",
    "            local_preds, global_preds = model(batch.clone())\n",
    "        else:\n",
    "            local_preds = model(batch.clone())\n",
    "        predicted.append(compute_lift_faces(batch, local_preds))\n",
    "        correct.append(compute_lift_faces(batch, batch.y))\n",
    "        \n",
    "    print(\"R2 score : \", getR2Score(torch.tensor(predicted), torch.tensor(correct)))\n",
    "        \n",
    "    return predicted, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SplineCNN4Pooling(3)\n",
    "model.load_state_dict(torch.load(\"Expirements/SplineCNN4Pooling.nn\"))\n",
    "r2scores, mses, pathes = getModelReport(model, global_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SplineCNN2(3)\n",
    "model.load_state_dict(torch.load(\"Expirements/Spline2CDF_sparse.nn\"))\n",
    "r2scores, mses, pathes = getModelReport(model, data_step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SplineCNN2(3)\n",
    "model.load_state_dict(torch.load(\"Expirements/Spline2CDF_sparse10.nn\"))\n",
    "r2scores, mses, pathes = getModelReport(model, data_step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SplineCNN2(3)\n",
    "model.load_state_dict(torch.load(\"Expirements/Spline2CDF.nn\"))\n",
    "r2scores, mses, pathes = getModelReport(model, data_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SplineCNN4(3)\n",
    "model.load_state_dict(torch.load(\"Expirements/Spline4CDF_sparse.nn\"))\n",
    "r2scores4, mses4, pathes4 = getModelReport(model, data_step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SplineCNN4(3)\n",
    "model.load_state_dict(torch.load(\"Expirements/Spline4CDF_sparse10.nn\"))\n",
    "r2scores, mses, pathes = getModelReport(model, data_step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SplineCNN4(3)\n",
    "model.load_state_dict(torch.load(\"Expirements/Spline4CDF.nn\"))\n",
    "r2scores, mses, pathes = getModelReport(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SplineCNN2(3)\n",
    "model.load_state_dict(torch.load(\"Expirements/Spline2CDF.nn\"))\n",
    "predicted, correct = getLiftModelReport(model, data_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SplineCNN2Pooling(3)\n",
    "model.load_state_dict(torch.load(\"Expirements/SplineCNN2PoolingNe.nn\"))\n",
    "r2_scores, msest, pathes = getModelReport(model, global_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, score in zip(pathes, r2_scores[:, 0]):\n",
    "    if score < 0:\n",
    "        print(score, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SplineCNN8Residuals(3)\n",
    "\n",
    "model.load_state_dict(torch.load(\"Expirements/SplineCNN8BatchNorm.nn\"))\n",
    "r2_scores, msest, pathes = getModelReport(model, global_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, score in zip(pathes, r2_scores[:, 0]):\n",
    "    if score < 0:\n",
    "        print(score, p)\n",
    "        \n",
    "print('=====')\n",
    "\n",
    "for p, score in zip(pathes, r2_scores[:, 0]):\n",
    "    if score >= 0:\n",
    "        print(score, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_shapes = [x for y,x in sorted(zip(r2scores[:, 0], range(len(r2scores)))) if y > 0]\n",
    "getR2Score(torch.tensor(predicted)[nice_shapes], torch.tensor(correct)[nice_shapes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse worst meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_shapes = [(y, x[0]) for y,x in sorted(zip(r2scores[:, 0], pathes)) if y < 0]\n",
    "for score, path in bad_shapes:\n",
    "    print(path, ' : ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score, path in bad_shapes:\n",
    "    data_instance = make_data_instance_from_fld(path)\n",
    "    saveMeshPly(data_instance.x, data_instance.y, 'Expirements/BadTestShapes/%s%.4f.ply' % (path.split('/')[-1][:4], score) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SplineCNN2(3)\n",
    "model.load_state_dict(torch.load(\"Expirements/Spline2CDF.nn\"))\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)\n",
    "\n",
    "for score, path in bad_shapes:\n",
    "    data_instance = make_data_instance_from_fld(path)\n",
    "    data_instance = data_instance.to(device)\n",
    "    prediction = model(data_instance)\n",
    "    saveMeshPly(data_instance.x.cpu().detach(), prediction.cpu().detach(), 'Expirements/BadTestShapes/Prediction%s%.4f.ply' % \n",
    "                (path.split('/')[-1][:4], score) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save mesh and get Global results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization_utils import saveMeshPly\n",
    "\n",
    "data_instance= make_data_instance_from_fld(\n",
    "                    '/cvlabsrc1/cvlab/dataset_shapenet/code/foam_npy/fld/0517_0005.fld')\n",
    "model = SplineCNN4Pooling(3)\n",
    "model.load_state_dict(torch.load(\"Expirements/SplineCNN4Pooling.nn\"))\n",
    "\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)\n",
    "loader = torch_geometric.data.DataLoader([data_instance], batch_size=1, shuffle=False)\n",
    "batch = next(iter(loader)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_preds, global_preds = model(batch.clone())\n",
    "local_preds, global_preds = local_preds.cpu().detach(), global_preds.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_preds = model(batch.clone())\n",
    "local_preds = local_preds.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_answers = list(data_instance.pressure_drag[0].numpy()) + list(data_instance.viscous_drag[0].numpy()) +\\\n",
    "                  list(data_instance.pressure_moment[0].numpy()) + list(data_instance.viscous_moment[0].numpy())\n",
    "\n",
    "print(\"Predicted : \", global_preds[0].numpy()[:3])\n",
    "print(\"            \", global_preds[0].numpy()[3:6])\n",
    "print(\"            \", global_preds[0].numpy()[6:9])\n",
    "print(\"            \", global_preds[0].numpy()[9:])\n",
    "print(\"GT        : \", stacked_answers[:3])\n",
    "print(\"            \", stacked_answers[3:6])\n",
    "print(\"            \", stacked_answers[6:9])\n",
    "print(\"            \", stacked_answers[9:])\n",
    "print()\n",
    "print(\"Pressure drag   : \", F.mse_loss(global_preds[:, :3], data_instance.pressure_drag).numpy())\n",
    "print(\"Viscous drag    : \", F.mse_loss(global_preds[:, 3:6], data_instance.viscous_drag).numpy())\n",
    "print(\"Pressure moment : \", F.mse_loss(global_preds[:, 6:9], data_instance.pressure_moment).numpy())\n",
    "print(\"Viscous moment  : \", F.mse_loss(global_preds[:, 9:], data_instance.viscous_moment).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveMeshPly(batch.x, batch.y, 'Expirements/BadTestShapes/517.ply')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a mapping from old names to new ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNmaesMapping(root):\n",
    "    mapping = {}\n",
    "    objects = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(os.path.join(root, 'scr')):\n",
    "        objects += [(os.path.join(dirpath, file), file[:-5]) for file in filenames if file[-5:] == '.json' and file[0] != '.']\n",
    "    for path, name in objects:\n",
    "        with open(path, 'r') as json_data:\n",
    "             origId = json.load(json_data)['stl_id']\n",
    "        mapping[origId] = name\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateNmaesMapping('/cvlabsrc1/cvlab/dataset_shapenet/code/foam_npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=np.copy(data_instance.y[:, 0])\n",
    "threshold = np.percentile(colors, 99.5)\n",
    "colors[colors > threshold] = threshold\n",
    "\n",
    "plt.hist(colors, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xadj = np.loadtxt('/cvlabsrc1/cvlab/dataset_shapenet/code/foam_npy/xadj/0000.xadj')\n",
    "fld = np.genfromtxt('/cvlabsrc1/cvlab/dataset_shapenet/code/foam_npy/fld/0000_0005.fld', delimiter=',', skip_header=1)\n",
    "\n",
    "fld_coords = sorted(fld[:, :3],key=lambda x: x[0])\n",
    "xadj_coords = sorted(xadj[:, :3], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xadj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fld.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xadj "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyntcloud import PyntCloud\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def plot_points_from_fld(fld, step_pt=2):\n",
    "    colors=np.copy(fld[:,3])\n",
    "    threshold = np.percentile(colors, 99.5)\n",
    "    colors[colors > threshold] = threshold\n",
    "    norm = mpl.colors.Normalize(vmin=np.min(colors), vmax=np.max(colors))\n",
    "    cmap = cm.hot\n",
    "    m = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    ax.scatter(-fld[::step_pt,2], fld[::step_pt,0], fld[::step_pt,1], s=5, c=m.to_rgba(colors[::step_pt]))\n",
    "    plt.colorbar(m)\n",
    "    ax.set_xlabel('X Label')\n",
    "    ax.set_ylabel('Y Label')\n",
    "    ax.set_zlabel('Z Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_points_from_fld(fld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=np.copy(fld[:,3])\n",
    "threshold = np.percentile(colors, 99.5)\n",
    "colors[colors > threshold] = threshold\n",
    "\n",
    "plt.hist(colors, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fld.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_utils import plot_points_from_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_points_from_torch(np.array(sorted(fld, key=lambda x: x[0]))[:, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_points_from_torch(np.array(sorted(xadj, key=lambda x: x[0]))[:, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk(\"/cvlabsrc1/cvlab/dataset_shapenet/code/foam_npy/fld/\"):\n",
    "    objects += [os.path.join(dirpath, file) for file in filenames if file[-4:] == '.fld']\n",
    "\n",
    "for path in objects:\n",
    "    a = np.genfromtxt(path, delimiter=',', skip_header=1)\n",
    "    if a.max() > 1e10: \n",
    "        print(a.max(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[80938]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trimesh Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SplineCNN8Residuals(3).cuda()\n",
    "model.load_state_dict(torch.load(\"Expirements/SplineCNN8BatchNorm.nn\"))\n",
    "#m = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_instance = make_data_instance_from_stl('/cvlabdata2/home/artem/Data/cars_refined/simulated/fld/0617_0005.fld')\n",
    "data_instance.to('cuda:0')\n",
    "#data_instance.y = 0\n",
    "prediction = model(data_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createColoredTrimesh(data_instance, target):\n",
    "    norm = mpl.colors.Normalize(vmin= -8, vmax=8)\n",
    "    cmap = cm.hot\n",
    "    m = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "    mesh = trimesh.Trimesh(vertices=data_instance.pos, \n",
    "                           faces=data_instance.face.t(),\n",
    "                           vertex_colors=list(map(lambda c: m.to_rgba(c),  target)))\n",
    "    \n",
    "    return mesh\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = createColoredTrimesh(data_instance.to('cpu'), data_instance.y[:, 0].cpu())\n",
    "mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mesh.export(\"../Expirements/savedMeshes/622gt.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = createColoredTrimesh(data_instance.to('cpu'), prediction[:, 0].cpu().detach())\n",
    "mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mesh.export(\"../Expirements/savedMeshes/622pr_train.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data_instance.y[:, 0], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(prediction[:, 0].cpu().detach(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[:, 0].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CDFDatasetInMemory('/cvlabdata2/home/artem/Data/cars_refined/simulated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CDFDatasetInMemory('/cvlabdata2/home/artem/Data/cars_refined/simulated', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch_geometric.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
