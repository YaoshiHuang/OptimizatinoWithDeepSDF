{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "\n",
    "import deep_sdf\n",
    "import deep_sdf.workspace as ws\n",
    "from models import *\n",
    "from datasets import *\n",
    "from custom_utils import *\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "import torch\n",
    "import numpy\n",
    "import trimesh\n",
    "import plyfile\n",
    "import numpy as np\n",
    "import numbers\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "\n",
    "def computeAvgTransform():\n",
    "    objects = list()\n",
    "    for (dirpath, dirnames, filenames) in os.walk(\"/cvlabdata2/home/artem/Data/cars_remeshed_dsdf/transforms/\"):\n",
    "        objects += [os.path.join(dirpath, file) for file in filenames if file[-4:] == '.npy']\n",
    "    \n",
    "    matricies = []\n",
    "    for obj in objects:\n",
    "        matricies.append(np.load(obj))\n",
    "    \n",
    "    return np.mean(np.array(matricies), axis=0)\n",
    "\n",
    "AvgTransform = computeAvgTransform()\n",
    "\n",
    "def transformPoints(points, matrix):\n",
    "    matrix = torch.cuda.FloatTensor(matrix)\n",
    "    column = torch.zeros((len(points), 1), device=\"cuda:0\") + 1\n",
    "    stacked = torch.cat([points, column], dim=1)\n",
    "    transformed = torch.matmul(matrix, stacked.T).T[:, :3]\n",
    "    return transformed\n",
    "\n",
    "def make_mesh_from_points(points, ply_mesh):\n",
    "    transformed_points = transformPoints(points, AvgTransform)\n",
    "    \n",
    "    edges = trimesh.geometry.faces_to_edges(ply_mesh['face']['vertex_indices'])\n",
    "    np_points = transformed_points.cpu().detach().numpy()\n",
    "    edge_attr = [np_points[a] - np_points[b] for a, b in edges]\n",
    "\n",
    "    data = torch_geometric.data.Data(x  = transformed_points, \n",
    "                                     pos= transformed_points, \n",
    "                                     face = torch.tensor(ply_mesh['face']['vertex_indices'], \n",
    "                                                         dtype=torch.long).to('cuda:0').t(),\n",
    "                                     edge_attr=torch.tensor(edge_attr, dtype=torch.float).to('cuda:0'),\n",
    "                                     edge_index=torch.tensor(edges, dtype=torch.long).t().contiguous().to('cuda:0'))\n",
    "    return data\n",
    "\n",
    "def boundsLoss(points, box=[(-1, 1, 0)]):\n",
    "    loss = 0\n",
    "    for l, r, i in box:\n",
    "        loss +=  torch.mean(F.relu(-points[:, i] + l))  \\\n",
    "               + torch.mean(F.relu( points[:, i] - r))\n",
    "    return loss\n",
    "\n",
    "def innerBoundsLoss(points, r=1, center=(0, 0, 0)):\n",
    "    radiuses = torch.sum( (points - torch.Tensor(center).to('cuda:0')) ** 2 , dim=1)\n",
    "    return torch.sum(F.relu(r - radiuses))\n",
    "\n",
    "def calculate_loss(mesh, local_preds, axis=0, constraint_rad=0.1):\n",
    "    loss =  (1 - axis) * compute_lift_faces_diff(mesh, local_preds, axis=0) + \\\n",
    "                  axis * compute_lift_faces_diff(mesh, local_preds, axis=1)\n",
    "    \n",
    "    loss += boundsLoss(mesh.x, box=[(-0.6, 0.6, 0)])\n",
    "    loss += innerBoundsLoss(mesh.x, r=(constraint_rad / 2)**2, center=(0.05, 0.05, 0))  \\\n",
    "          + innerBoundsLoss(mesh.x, r=(constraint_rad / 2)**2, center=(-0.3, 0, 0))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205 of latent vectors, each 1 long\n"
     ]
    }
   ],
   "source": [
    "experiment_directory = \"/cvlabdata2/home/artem/DeepSDF/examples/cars_cleared/\"\n",
    "checkpoint = \"latest\"\n",
    "decoder = load_model(experiment_directory, checkpoint).to('cuda:0')\n",
    "\n",
    "latent_vectors = ws.load_latent_vectors(experiment_directory, checkpoint)\n",
    "latent_size = latent_vectors[0].size()[0]\n",
    "print(f\"{len(latent_vectors)} of latent vectors, each {latent_size} long\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trilinear_interpolate(grid, samples):\n",
    "    \"\"\"\n",
    "    Interpolate 3D samples on cartesian grid of values.\n",
    "    Note that the code assumes samples bounding box to \n",
    "    be alligned to cartesian grid.\n",
    "    \n",
    "    input:\n",
    "    image \\in [B,C,W,W,W]\n",
    "    samples \\in [B,N,3]\n",
    "\n",
    "    output:\n",
    "    interpolated_samples \\in [B,N,C]\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    W = grid.shape[-1]\n",
    "    samples = samples.unsqueeze(2).unsqueeze(3).unsqueeze(3)\n",
    "    samples = (samples[:,:,:,0]/(W-1)) # normalize to between  0 and 1\n",
    "    samples = samples*2-1 # normalize to between -1 and 1\n",
    "    interpolated_samples = torch.nn.functional.grid_sample(grid, samples)\n",
    "    return interpolated_samples.squeeze(-1).squeeze(-1).permute(0,2,1)\n",
    "\n",
    "def write_verts_faces_to_file(verts, faces, ply_filename_out):\n",
    "\n",
    "    num_verts = verts.shape[0]\n",
    "    num_faces = faces.shape[0]\n",
    "\n",
    "    verts_tuple = np.zeros((num_verts,), dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\")])\n",
    "\n",
    "    for i in range(0, num_verts):\n",
    "        verts_tuple[i] = tuple(verts[i, :])\n",
    "\n",
    "    faces_building = []\n",
    "    for i in range(0, num_faces):\n",
    "        faces_building.append(((faces[i, :].tolist(),)))\n",
    "    faces_tuple = np.array(faces_building, dtype=[(\"vertex_indices\", \"i4\", (3,))])\n",
    "\n",
    "    el_verts = plyfile.PlyElement.describe(verts_tuple, \"vertex\")\n",
    "    el_faces = plyfile.PlyElement.describe(faces_tuple, \"face\")\n",
    "\n",
    "    ply_data = plyfile.PlyData([el_verts, el_faces])\n",
    "    ply_data.write(ply_filename_out)\n",
    "    \n",
    "\n",
    "class GaussianSmoothing(nn.Module):\n",
    "    \"\"\"\n",
    "    Apply gaussian smoothing on a\n",
    "    1d, 2d or 3d tensor. Filtering is performed seperately for each channel\n",
    "    in the input using a depthwise convolution.\n",
    "    Arguments:\n",
    "        channels (int, sequence): Number of channels of the input tensors. Output will\n",
    "            have this number of channels as well.\n",
    "        kernel_size (int, sequence): Size of the gaussian kernel.\n",
    "        sigma (float, sequence): Standard deviation of the gaussian kernel.\n",
    "        dim (int, optional): The number of dimensions of the data.\n",
    "            Default value is 2 (spatial).\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, kernel_size, sigma, dim=3):\n",
    "        super(GaussianSmoothing, self).__init__()\n",
    "        if isinstance(kernel_size, numbers.Number):\n",
    "            kernel_size = [kernel_size] * dim\n",
    "        if isinstance(sigma, numbers.Number):\n",
    "            sigma = [sigma] * dim\n",
    "\n",
    "        # The gaussian kernel is the product of the\n",
    "        # gaussian function of each dimension.\n",
    "        kernel = 1\n",
    "        meshgrids = torch.meshgrid(\n",
    "            [\n",
    "                torch.arange(size, dtype=torch.float32)\n",
    "                for size in kernel_size\n",
    "            ]\n",
    "        )\n",
    "        for size, std, mgrid in zip(kernel_size, sigma, meshgrids):\n",
    "            mean = (size - 1) / 2\n",
    "            kernel *= 1 / (std * math.sqrt(2 * math.pi)) * \\\n",
    "                      torch.exp(-((mgrid - mean) / (2 * std)) ** 2)\n",
    "\n",
    "        # Make sure sum of values in gaussian kernel equals 1.\n",
    "        kernel = kernel / torch.sum(kernel)\n",
    "\n",
    "        # Reshape to depthwise convolutional weight\n",
    "        kernel = kernel.view(1, 1, *kernel.size())\n",
    "        kernel = kernel.repeat(channels, *[1] * (kernel.dim() - 1))\n",
    "\n",
    "        self.register_buffer('weight', kernel)\n",
    "        self.groups = channels\n",
    "\n",
    "        if dim == 1:\n",
    "            self.conv = F.conv1d\n",
    "        elif dim == 2:\n",
    "            self.conv = F.conv2d\n",
    "        elif dim == 3:\n",
    "            self.conv = F.conv3d\n",
    "        else:\n",
    "            raise RuntimeError(\n",
    "                'Only 1, 2 and 3 dimensions are supported. Received {}.'.format(dim)\n",
    "            )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Apply gaussian filter to input.\n",
    "        Arguments:\n",
    "            input (torch.Tensor): Input to apply gaussian filter on.\n",
    "        Returns:\n",
    "            filtered (torch.Tensor): Filtered output.\n",
    "        \"\"\"\n",
    "        return self.conv(input, weight=self.weight, groups=self.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_parameterization(mesh, displacement_grid,  GRID_RESOLUTION=8, padding=0.2):\n",
    "    answ = mesh.clone()\n",
    "    # first go from DeepSDF bounding box [-1,1]^3 to GRID [0,GRID_RESOLUTION]^3\n",
    "    shifts = torch.min(answ.x, axis=0).values\n",
    "    scales = (torch.max(answ.x, axis=0).values - torch.min(answ.x, axis=0).values)\n",
    "    verticies_0_1 = (answ.x - shifts) / scales\n",
    "                    \n",
    "    vertices_in_grid = GRID_RESOLUTION*(verticies_0_1 + padding) / (1 + 2 * padding)\n",
    "    # now read up displacement \n",
    "    vertices_displacement = trilinear_interpolate(displacement_grid.unsqueeze(0), \n",
    "                                                  vertices_in_grid.unsqueeze(0)).squeeze(0)\n",
    "    # and sum it to original position\n",
    "    vertices_displaced = vertices_displacement + vertices_in_grid\n",
    "    \n",
    "    # finally go back to DeepSDF bounding box\n",
    "    answ.x = (vertices_displaced / GRID_RESOLUTION * (1 + 2 * padding) - padding)  * scales + shifts\n",
    "    answ.pos = answ.x\n",
    "#     attrs = (answ.x[ mesh.edge_index[0] ] - answ.x[mesh.edge_index[1]]).detach().cpu().numpy()\n",
    "#     answ.edge_attr = torch.tensor(attrs, dtype=torch.float).to('cuda:0')\n",
    "\n",
    "#     print(torch.max( torch.sum((mesh.edge_attr -  answ.edge_attr)**2, axis=1))) \n",
    "    return answ\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_shape_as_umetami(model, inp, num_iters=100, save_to_dir='Expirements/Optimization',\n",
    "                   lr=0.05, decreased_by=2, adjust_lr_every=10, verbose=None, constraint_rad=0.1, \n",
    "                              GRID_RESOLUTION = 8,axis=0):\n",
    "    \n",
    "    def adjust_learning_rate(\n",
    "        initial_lr, optimizer, num_iterations, decreased_by, adjust_lr_every\n",
    "    ):\n",
    "        lr = initial_lr * ((1 / decreased_by) ** (num_iterations // adjust_lr_every))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "            \n",
    "        return lr\n",
    "\n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'meshes')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'meshes'))\n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'predictions')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'predictions'))\n",
    "\n",
    "    model.eval()\n",
    "    data_instance = inp.clone()\n",
    "#     data_instance.x.requires_grad = True\n",
    "    \n",
    "    \n",
    "    params = torch.zeros(( 3, GRID_RESOLUTION, GRID_RESOLUTION, GRID_RESOLUTION), \n",
    "                            dtype=torch.float).to('cuda:0')\n",
    "    params.requires_grad = True\n",
    "\n",
    "    optimizer = torch.optim.SGD([params], lr=lr)\n",
    "\n",
    "    meshes = []\n",
    "    lifts = []\n",
    "    lr_plot = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        cur_rl = adjust_learning_rate(lr, optimizer, i, decreased_by, adjust_lr_every)\n",
    "        save_path = os.path.join(save_to_dir, 'meshes/' + str(i).zfill(5) + \".ply\")\n",
    "        preds_save_path = os.path.join(save_to_dir, 'predictions/' + str(i).zfill(5) + \".npy\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get displacement grid\n",
    "        p3d = (2, 2, 2, 2, 2, 2) \n",
    "        displacement_grid = F.pad(params, p3d, \"constant\", 0)\n",
    "        smoothing = GaussianSmoothing(3, 5, 1).to('cuda:0')\n",
    "        displacement_grid = smoothing(displacement_grid.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        # we also probably want the displacement to be limited to the dsize of a voxel cell\n",
    "        displacement_grid = 0.5*torch.tanh(displacement_grid)\n",
    "        \n",
    "        \n",
    "        # transform mesh\n",
    "        transformed_mesh = apply_parameterization(data_instance, displacement_grid, GRID_RESOLUTION=GRID_RESOLUTION)\n",
    "\n",
    "        local_preds = model(transformed_mesh)\n",
    "        loss = calculate_loss(transformed_mesh, local_preds, axis=axis, constraint_rad=constraint_rad)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if verbose is not None and i % verbose == 0:\n",
    "            print('Iter %4d ' % i, 'Loss: %0.5f ' % loss.detach().cpu().numpy(), ' LR: %0.5f ' % cur_rl, \n",
    "                  'Params norm: %0.3f ' % torch.sum(displacement_grid ** 2).detach().cpu().numpy(),\n",
    "                  'Number params affected: %d ' % torch.sum(torch.sum(displacement_grid**2, axis=0) > 0.05).detach().cpu().numpy())\n",
    "                #plot_points_from_torch(points)\n",
    "\n",
    "        tri_mesh = get_trimesh_from_torch_geo_with_colors(transformed_mesh, local_preds)\n",
    "        tri_mesh.export(save_path)\n",
    "        np.save(preds_save_path, local_preds.cpu().detach().numpy())\n",
    "\n",
    "        lifts.append(loss.detach().cpu().numpy())\n",
    "        lr_plot.append(cur_rl)\n",
    "\n",
    "        np.save(os.path.join(save_to_dir, \"loss_plot.npy\"), lifts)\n",
    "        np.save(os.path.join(save_to_dir, \"lr_plot.npy\"), lr_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "#model = SplineCNN8(3, batchnorm1=False)\n",
    "#model.load_state_dict(torch.load(\"Expirements/SplineCNN8.nn\"))\n",
    "model = SplineCNN8Residuals(3)\n",
    "model.load_state_dict(torch.load(\"Expirements/Networks15/normilized_full_latest.nn\"))\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(mesh, local_preds, axis=0, constraint_rad=0.1):\n",
    "    loss =  (1 - axis) * compute_lift_faces_diff(mesh, local_preds, axis=0) + \\\n",
    "                  axis * compute_lift_faces_diff(mesh, local_preds, axis=1)\n",
    "    loss += boundsLoss(mesh.x, box=[(-0.6, 0.6, 0)])\n",
    "    loss += innerBoundsLoss(mesh.x, r=(constraint_rad / 2)**2, center=(0.05, 0.05, 0))  \\\n",
    "          + innerBoundsLoss(mesh.x, r=(constraint_rad / 2)**2, center=(-0.3, 0, 0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter    0  Loss: 0.05752   LR: 1000.00000  Params norm: 0.000  Number params affected: 0 \n",
      "Iter   25  Loss: -0.05255   LR: 250.00000  Params norm: 67.130  Number params affected: 346 \n",
      "Iter    0  Loss: 0.07473   LR: 1000.00000  Params norm: 0.000  Number params affected: 0 \n",
      "Iter   25  Loss: -0.03357   LR: 250.00000  Params norm: 52.033  Number params affected: 303 \n",
      "Iter    0  Loss: 0.11710   LR: 1000.00000  Params norm: 0.000  Number params affected: 0 \n",
      "Iter   25  Loss: -0.01405   LR: 250.00000  Params norm: 69.313  Number params affected: 394 \n"
     ]
    }
   ],
   "source": [
    "N=256\n",
    "\n",
    "for LETENT_IDX in [535, 113, 69]:\n",
    "    LATENT_TO_OPTIMIZE = latent_vectors[LETENT_IDX]\n",
    "    LATENT_KD_TREE = KDTree(np.array([lv.cpu().detach().numpy()[0] for lv in latent_vectors]))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ply_mesh = create_mesh( decoder,\n",
    "                                LATENT_TO_OPTIMIZE,\n",
    "                                N=N,\n",
    "                                max_batch=int(2 ** 18),\n",
    "                                offset=None,\n",
    "                                scale=None)\n",
    "\n",
    "    points = torch.cuda.FloatTensor(np.hstack(( ply_mesh['vertex']['x'][:, None], \n",
    "                                            ply_mesh['vertex']['y'][:, None], \n",
    "                                            ply_mesh['vertex']['z'][:, None])))\n",
    "\n",
    "    MESH_TO_OPTIMIZE = make_mesh_from_points(points, ply_mesh)\n",
    "    MESH_TO_OPTIMIZE.to('cuda:0')\n",
    "    \n",
    "    optimize_shape_as_umetami(model, MESH_TO_OPTIMIZE, verbose=25, lr=1e3, axis=0, GRID_RESOLUTION = 8, num_iters=30,\n",
    "                          save_to_dir='Expirements/OptimizationPaper/AfterMeeting/UmetamiDrag2/%04dplus' % LETENT_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_RESOLUTION=8\n",
    "params = torch.zeros(( 3, GRID_RESOLUTION, GRID_RESOLUTION, GRID_RESOLUTION), \n",
    "                            dtype=torch.float).to('cuda:0')\n",
    "params.requires_grad = True\n",
    "# Get displacement grid\n",
    "p3d = (2, 2, 2, 2, 2, 2) \n",
    "displacement_grid = F.pad(params, p3d, \"constant\", 0)\n",
    "smoothing = GaussianSmoothing(3, 5, 1).to('cuda:0')\n",
    "displacement_grid = smoothing(displacement_grid.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "# we also probably want the displacement to be limited to the dsize of a voxel cell\n",
    "displacement_grid = 0.5*torch.tanh(displacement_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
