{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import (NNConv, GMMConv, GraphConv, Set2Set)\n",
    "from torch_geometric.nn import (SplineConv, graclus, max_pool, max_pool_x, global_mean_pool)\n",
    "\n",
    "#from neuralnet_pytorch.metrics import chamfer_loss\n",
    "\n",
    "import trimesh\n",
    "\n",
    "from visualization_utils import plot_mesh_3d\n",
    "\n",
    "import deep_sdf\n",
    "import deep_sdf.workspace as ws\n",
    "from models import *\n",
    "from datasets import *\n",
    "from custom_utils import *\n",
    "\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAvgTransform():\n",
    "    objects = list()\n",
    "    for (dirpath, dirnames, filenames) in os.walk(\"/cvlabdata2/home/artem/Data/cars_remeshed_dsdf/transforms/\"):\n",
    "        objects += [os.path.join(dirpath, file) for file in filenames if file[-4:] == '.npy']\n",
    "    \n",
    "    matricies = []\n",
    "    for obj in objects:\n",
    "        matricies.append(np.load(obj))\n",
    "    \n",
    "    return np.mean(np.array(matricies), axis=0)\n",
    "\n",
    "AvgTransform = computeAvgTransform()\n",
    "\n",
    "def transformPoints(points, matrix):\n",
    "    matrix = torch.cuda.FloatTensor(matrix)\n",
    "    column = torch.zeros((len(points), 1), device=\"cuda:0\") + 1\n",
    "    stacked = torch.cat([points, column], dim=1)\n",
    "    transformed = torch.matmul(matrix, stacked.T).T[:, :3]\n",
    "    return transformed\n",
    "\n",
    "def make_mesh_from_points(points, ply_mesh):\n",
    "    transformed_points = transformPoints(points, AvgTransform)\n",
    "    \n",
    "    edges = trimesh.geometry.faces_to_edges(ply_mesh['face']['vertex_indices'])\n",
    "    np_points = transformed_points.cpu().detach().numpy()\n",
    "    edge_attr = [np_points[a] - np_points[b] for a, b in edges]\n",
    "\n",
    "    data = torch_geometric.data.Data(x  = transformed_points, \n",
    "                                     pos= transformed_points, \n",
    "                                     face = torch.tensor(ply_mesh['face']['vertex_indices'], \n",
    "                                                         dtype=torch.long).to('cuda:0').t(),\n",
    "                                     edge_attr=torch.tensor(edge_attr, dtype=torch.float).to('cuda:0'),\n",
    "                                     edge_index=torch.tensor(edges, dtype=torch.long).t().contiguous().to('cuda:0'))\n",
    "    return data\n",
    "\n",
    "\n",
    "def boundsLoss(points, box=[(-1, 1, 0)]):\n",
    "    loss = 0\n",
    "    for l, r, i in box:\n",
    "        loss +=  torch.sum(F.relu(-points[:, i] + l)) + torch.sum(F.relu(points[:, i] - r))\n",
    "    return loss\n",
    "\n",
    "def innerBoundsLoss(points, r=1, center=(0, 0, 0)):\n",
    "    radiuses = torch.sum( (points - torch.Tensor(center).to('cuda:0')) ** 2 , dim=1)\n",
    "    return torch.sum(F.relu(r - radiuses))\n",
    "\n",
    "def calculate_loss(mesh, local_preds, signs=None, axis=0, constraint_rad=0.1):\n",
    "#     if signs is None:\n",
    "#         signs = SAVED_SIGNS\n",
    "    loss =  (1 - axis) * compute_lift_faces_diff(mesh, local_preds, axis=0) + \\\n",
    "                  axis * compute_lift_faces_diff(mesh, local_preds, axis=1)\n",
    "    loss += boundsLoss(points, box=[(-0.99, 0.99, 0)])\n",
    "    loss += innerBoundsLoss(points, r=(constraint_rad * 2)**2) \\\n",
    "          + innerBoundsLoss(points, r=constraint_rad**2, center=(0.55, 0, 0))\n",
    "    \n",
    "    #loss = compute_lift_faces_diff_signs(mesh, local_preds, axis=axis)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import (NNConv, GMMConv, GraphConv, Set2Set)\n",
    "from torch_geometric.nn import (SplineConv, graclus, max_pool, max_pool_x, global_mean_pool)\n",
    "\n",
    "class SplineBlock(nn.Module):\n",
    "    def __init__(self, num_in_features, num_outp_features, mid_features, kernel=3, dim=3):\n",
    "        super(SplineBlock, self).__init__()\n",
    "        self.conv1 = SplineConv(num_in_features, mid_features, dim, kernel, is_open_spline=False)\n",
    "#        self.batchnorm1 = torch.nn.BatchNorm1d(mid_features)\n",
    "        self.conv2 = SplineConv(mid_features, 2 * mid_features, dim, kernel, is_open_spline=False)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(2 * mid_features)\n",
    "        self.conv3 = SplineConv(2 * mid_features + 3, num_outp_features, dim, kernel, is_open_spline=False)\n",
    "  \n",
    "    def forward(self, res, data):\n",
    "#        res = F.elu(self.batchnorm1(self.conv1(res, data.edge_index, data.edge_attr)))\n",
    "        res = F.elu(self.conv1(res, data.edge_index, data.edge_attr))\n",
    "        res = F.elu(self.batchnorm2(self.conv2(res, data.edge_index, data.edge_attr)))\n",
    "#         res = F.elu(self.conv2(res, data.edge_index, data.edge_attr))\n",
    "        res = torch.cat([res, data.pos], dim=1)\n",
    "        res = self.conv3(res, data.edge_index, data.edge_attr)\n",
    "        return res\n",
    "    \n",
    "class SplineCNN8(nn.Module):\n",
    "    def __init__(self, num_features, kernel=3, dim=3):\n",
    "        super(SplineCNN8, self).__init__()\n",
    "        self.block1 = SplineBlock(num_features, 16, 8, kernel, dim)\n",
    "        self.block2 = SplineBlock(16, 64, 32, kernel, dim)\n",
    "        self.block3 = SplineBlock(64, 64, 128, kernel, dim)\n",
    "        self.block4 = SplineBlock(64, 8, 16, kernel, dim)\n",
    "        self.block5 = SplineBlock(8, 32, 16, kernel, dim)\n",
    "        self.block6 = SplineBlock(32, 64, 32, kernel, dim)\n",
    "        self.block7 = SplineBlock(64, 64, 128, kernel, dim)\n",
    "        self.block8 = SplineBlock(64, 4, 16, kernel, dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        res = data.x\n",
    "        res = self.block1(res, data)\n",
    "        res = self.block2(res, data)\n",
    "        res = self.block3(res, data)\n",
    "        res = self.block4(res, data)\n",
    "        res = self.block5(res, data)\n",
    "        res = self.block6(res, data)\n",
    "        res = self.block7(res, data)\n",
    "        res = self.block8(res, data)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_instance= make_data_instance_from_stl(\n",
    "#                '/cvlabdata2/home/artem/Data/cars_remeshed_dsdf/outputs/fld/0003_0015.fld') # /cvlabdata2/home/artem/Data/cars_refined/simulated/fld/0002_0005.fld\n",
    "model = SplineCNN8(3)\n",
    "model.load_state_dict(torch.load(\"Expirements/SplineCNN8.nn\"))\n",
    "\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205 of latent vectors, each 1 long\n"
     ]
    }
   ],
   "source": [
    "experiment_directory = \"/cvlabdata2/home/artem/DeepSDF/examples/cars_cleared/\"\n",
    "checkpoint = \"latest\"\n",
    "decoder = load_model(experiment_directory, checkpoint)\n",
    "\n",
    "latent_vectors = ws.load_latent_vectors(experiment_directory, checkpoint)\n",
    "latent_size = latent_vectors[0].size()[0]\n",
    "print(f\"{len(latent_vectors)} of latent vectors, each {latent_size} long\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertex-vise Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_shape_by_vertex(model, inp, num_iters=30, save_to_dir='Expirements/Optimization',\n",
    "                   lr=0.05, decreased_by=2, adjust_lr_every=10, verbose=None, constraint_rad=0.1, axis=0):\n",
    "\n",
    "    def adjust_learning_rate(\n",
    "        initial_lr, optimizer, num_iterations, decreased_by, adjust_lr_every\n",
    "    ):\n",
    "        lr = initial_lr * ((1 / decreased_by) ** (num_iterations // adjust_lr_every))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "            \n",
    "        return lr\n",
    "    \n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'meshes')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'meshes'))\n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'predictions')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'predictions'))\n",
    "    \n",
    "    try:\n",
    "        model.eval()\n",
    "        data_instance = inp.clone()\n",
    "        data_instance.x.requires_grad = True\n",
    "        optimizer = torch.optim.SGD([data_instance.x], lr=lr)\n",
    "\n",
    "        meshes = []\n",
    "        lifts = []\n",
    "        lr_plot = []\n",
    "\n",
    "        for i in range(num_iters):\n",
    "            cur_lr = adjust_learning_rate(lr, optimizer, i, decreased_by, adjust_lr_every)\n",
    "            \n",
    "            save_path = os.path.join(save_to_dir, 'meshes/' + str(i).zfill(5) + \".ply\")\n",
    "            preds_save_path = os.path.join(save_to_dir, 'predictions/' + str(i).zfill(5) + \".npy\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            local_preds = model(data_instance)\n",
    "            # Don't ask me why\n",
    "            points_in_deepSDF = transformPoints(data_instance.x, np.linalg.inv(AvgTransform))\n",
    "            \n",
    "            #print(points_in_deepSDF)\n",
    "            loss = calculate_loss(data_instance, local_preds, axis, constraint_rad=constraint_rad)\n",
    "            \n",
    "            loss.backward()\n",
    "            #print('Avg grad: ', torch.mean(torch.sum(data_instance.x.grad ** 2, axis=1)))\n",
    "            \n",
    "            tri_mesh = get_trimesh_from_torch_geo_with_colors(data_instance, local_preds)\n",
    "            tri_mesh.export(save_path)\n",
    "            np.save(preds_save_path, local_preds.cpu().detach().numpy())\n",
    "            \n",
    "#             data_instance.x.grad[torch.isnan(data_instance.x.grad)] = 0\n",
    "            optimizer.step()\n",
    "\n",
    "            if verbose is not None and i % verbose == 0:\n",
    "                print('Iter ', i, 'Loss: ', loss.detach().cpu().numpy(), ' LR: ', cur_lr)\n",
    "                    #plot_points_from_torch(points)\n",
    "            \n",
    "            lifts.append(loss.detach().cpu().numpy())\n",
    "            lr_plot.append(cur_lr)\n",
    "            np.save(os.path.join(save_to_dir, \"loss_plot.npy\"), lifts)\n",
    "            np.save(os.path.join(save_to_dir, \"lr_plot.npy\"), lr_plot)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Paused\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize_shape_by_vertex(model, MESH_TO_OPTIMIZE, verbose=1, save_to_dir='Expirements/OptimizationPaper/NewGenVertexDragTight', \n",
    "#                          lr=0.002, adjust_lr_every=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BB Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_shape_by_scaling(model, inp, num_iters=100, save_to_dir='Expirements/Optimization',\n",
    "                   lr=0.05, decreased_by=2, adjust_lr_every=10, verbose=None, constraint_rad=0.1, axis=0):\n",
    "\n",
    "    def transform(data, scale):\n",
    "        answ = data.clone()\n",
    "        answ.x = data.x * scale\n",
    "        return answ\n",
    "    \n",
    "    def adjust_learning_rate(\n",
    "        initial_lr, optimizer, num_iterations, decreased_by, adjust_lr_every\n",
    "    ):\n",
    "        lr = initial_lr * ((1 / decreased_by) ** (num_iterations // adjust_lr_every))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "            \n",
    "        return lr\n",
    "\n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'meshes')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'meshes'))\n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'predictions')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'predictions'))\n",
    "\n",
    "    try:\n",
    "        model.eval()\n",
    "        data_instance = inp.clone()\n",
    "        data_instance.x.requires_grad = True\n",
    "        scale = torch.Tensor([1.0, 1.0, 1.0]).to(\"cuda:0\")\n",
    "        scale.requires_grad = True\n",
    "\n",
    "        optimizer = torch.optim.SGD([scale], lr=lr)\n",
    "\n",
    "        meshes = []\n",
    "        lifts = []\n",
    "        lr_plot = []\n",
    "\n",
    "        for i in range(num_iters):\n",
    "            cur_rl = adjust_learning_rate(lr, optimizer, i, decreased_by, adjust_lr_every)\n",
    "            save_path = os.path.join(save_to_dir, 'meshes/' + str(i).zfill(5) + \".ply\")\n",
    "            preds_save_path = os.path.join(save_to_dir, 'predictions/' + str(i).zfill(5) + \".npy\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            transformed_mesh = transform(data_instance, scale)\n",
    "            \n",
    "            # Restriction\n",
    "            # min_dist = compute_min_distance(transformed_mesh)\n",
    "            # scale_clapped = scale * min(1, GLOBAL_MIN_DIST / min_dist)\n",
    "            #transformed_mesh = transform(data_instance, scale)\n",
    "                \n",
    "            local_preds = model(transformed_mesh)\n",
    "            points_in_deepSDF = transformPoints(transformed_mesh.x, np.linalg.inv(AvgTransform))\n",
    "            loss = calculate_loss(transformed_mesh, local_preds, axis=axis, constraint_rad=constraint_rad)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if verbose is not None and i % verbose == 0:\n",
    "                print('Iter ', i, 'Loss: ', loss.detach().cpu().numpy(), ' LR: ', cur_rl)\n",
    "                    #plot_points_from_torch(points)\n",
    "                    \n",
    "            tri_mesh = get_trimesh_from_torch_geo_with_colors(transformed_mesh, local_preds)\n",
    "            tri_mesh.export(save_path)\n",
    "            np.save(preds_save_path, local_preds.cpu().detach().numpy())\n",
    "\n",
    "            lifts.append(loss.detach().cpu().numpy())\n",
    "            lr_plot.append(cur_rl)\n",
    "            \n",
    "            np.save(os.path.join(save_to_dir, \"loss_plot.npy\"), lifts)\n",
    "            np.save(os.path.join(save_to_dir, \"lr_plot.npy\"), lr_plot)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Paused\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize_shape_by_scaling(model, MESH_TO_OPTIMIZE, verbose=1, save_to_dir='Expirements/OptimizationPaper/BboxDragDiff', lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free Foam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_shape_as_pierre(model, inp, num_iters=100, save_to_dir='Expirements/Optimization',\n",
    "                   lr=0.05, decreased_by=2, adjust_lr_every=10, verbose=None, constraint_rad=0.1, axis=0):\n",
    "\n",
    "    def transform(data, scale):\n",
    "        answ = data.clone()\n",
    "        answ.x = \\\n",
    "            data.x * (scale[1] + scale[2] * data.x + \\\n",
    "                      scale[3] * torch.cos(data.x[:, (2, 0, 1)] * 2 * math.pi) + \\\n",
    "                      scale[4] * torch.cos(data.x[:, (1, 2, 0)] * 2 * math.pi) + \\\n",
    "                      scale[5] * torch.sin(data.x[:, (2, 0, 1)] * 2 * math.pi) + \\\n",
    "                      scale[5] * torch.sin(data.x[:, (1, 2, 0)] * 2 * math.pi))\n",
    "        return answ\n",
    "    \n",
    "    def adjust_learning_rate(\n",
    "        initial_lr, optimizer, num_iterations, decreased_by, adjust_lr_every\n",
    "    ):\n",
    "        lr = initial_lr * ((1 / decreased_by) ** (num_iterations // adjust_lr_every))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "            \n",
    "        return lr\n",
    "\n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'meshes')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'meshes'))\n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'predictions')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'predictions'))\n",
    "\n",
    "    try:\n",
    "        model.eval()\n",
    "        data_instance = inp.clone()\n",
    "        data_instance.x.requires_grad = True\n",
    "        scale = torch.Tensor([[0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                              [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                              [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]]).to(\"cuda:0\").t()\n",
    "        scale.requires_grad = True\n",
    "\n",
    "        optimizer = torch.optim.SGD([scale], lr=lr)\n",
    "\n",
    "        meshes = []\n",
    "        lifts = []\n",
    "        lr_plot = []\n",
    "\n",
    "        for i in range(num_iters):\n",
    "            cur_rl = adjust_learning_rate(lr, optimizer, i, decreased_by, adjust_lr_every)\n",
    "            save_path = os.path.join(save_to_dir, 'meshes/' + str(i).zfill(5) + \".ply\")\n",
    "            preds_save_path = os.path.join(save_to_dir, 'predictions/' + str(i).zfill(5) + \".npy\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            transformed_mesh = transform(data_instance, scale)\n",
    "                \n",
    "            local_preds = model(transformed_mesh)\n",
    "            points_in_deepSDF = transformPoints(transformed_mesh.x, np.linalg.inv(AvgTransform))\n",
    "            loss = calculate_loss(transformed_mesh, local_preds, axis=axis, constraint_rad=constraint_rad)\n",
    "\n",
    "            loss.backward()\n",
    "#             print(\"Grad: \", scale.grad)\n",
    "            optimizer.step()\n",
    "\n",
    "            if verbose is not None and i % verbose == 0:\n",
    "                print('Iter ', i, 'Loss: ', loss.detach().cpu().numpy(), ' LR: ', cur_rl)\n",
    "                    #plot_points_from_torch(points)\n",
    "                    \n",
    "            tri_mesh = get_trimesh_from_torch_geo_with_colors(transformed_mesh, local_preds)\n",
    "            tri_mesh.export(save_path)\n",
    "            np.save(preds_save_path, local_preds.cpu().detach().numpy())\n",
    "\n",
    "            lifts.append(loss.detach().cpu().numpy())\n",
    "            lr_plot.append(cur_rl)\n",
    "            \n",
    "            np.save(os.path.join(save_to_dir, \"loss_plot.npy\"), lifts)\n",
    "            np.save(os.path.join(save_to_dir, \"lr_plot.npy\"), lr_plot)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Paused\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize_shape_as_pierre(model, MESH_TO_OPTIMIZE, verbose=1, \n",
    "#                          save_to_dir='Expirements/OptimizationPaper/PierreDragDiff', lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free Foam Furrier Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_shape_as_pierre_furrier(model, inp, num_params=88, num_iters=100, save_to_dir='Expirements/Optimization',\n",
    "                   lr=0.05, decreased_by=2, adjust_lr_every=10, verbose=None, constraint_rad=0.1, axis=0):\n",
    "\n",
    "    def transform(data, scale):\n",
    "        answ = data.clone()\n",
    "        answ.x = scale[0] + \\\n",
    "            data.x * (scale[1] + scale[2] * data.x)\n",
    "        for k, idx in enumerate(range(3, num_params - 3, 4)):\n",
    "            answ.x += data.x * (scale[idx + 0] * torch.cos((k + 1) * data.x[:, (2, 0, 1)] * 2 * math.pi) + \\\n",
    "                                scale[idx + 1] * torch.cos((k + 1) * data.x[:, (1, 2, 0)] * 2 * math.pi) + \\\n",
    "                                scale[idx + 2] * torch.sin((k + 1) * data.x[:, (2, 0, 1)] * 2 * math.pi) + \\\n",
    "                                scale[idx + 3] * torch.sin((k + 1) * data.x[:, (1, 2, 0)] * 2 * math.pi))\n",
    "        return answ\n",
    "    \n",
    "    def adjust_learning_rate(\n",
    "        initial_lr, optimizer, num_iterations, decreased_by, adjust_lr_every\n",
    "    ):\n",
    "        lr = initial_lr * ((1 / decreased_by) ** (num_iterations // adjust_lr_every))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "            \n",
    "        return lr\n",
    "\n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'meshes')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'meshes'))\n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'predictions')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'predictions'))\n",
    "\n",
    "    try:\n",
    "        model.eval()\n",
    "        data_instance = inp.clone()\n",
    "        data_instance.x.requires_grad = True\n",
    "        scale = torch.zeros((3, num_params), dtype=torch.float).to(\"cuda:0\").t()\n",
    "        scale[1] = 1\n",
    "        scale.requires_grad = True\n",
    "\n",
    "        optimizer = torch.optim.SGD([scale], lr=lr)\n",
    "\n",
    "        meshes = []\n",
    "        lifts = []\n",
    "        lr_plot = []\n",
    "\n",
    "        for i in range(num_iters):\n",
    "            cur_rl = adjust_learning_rate(lr, optimizer, i, decreased_by, adjust_lr_every)\n",
    "            save_path = os.path.join(save_to_dir, 'meshes/' + str(i).zfill(5) + \".ply\")\n",
    "            preds_save_path = os.path.join(save_to_dir, 'predictions/' + str(i).zfill(5) + \".npy\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            transformed_mesh = transform(data_instance, scale)\n",
    "                \n",
    "            local_preds = model(transformed_mesh)\n",
    "            points_in_deepSDF = transformPoints(transformed_mesh.x, np.linalg.inv(AvgTransform))\n",
    "            loss = calculate_loss(transformed_mesh, local_preds, axis=axis, constraint_rad=constraint_rad) \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if verbose is not None and i % verbose == 0:\n",
    "                print('Iter ', i, 'Loss: ', loss.detach().cpu().numpy(), ' LR: ', cur_rl)\n",
    "                    #plot_points_from_torch(points)\n",
    "                    \n",
    "            tri_mesh = get_trimesh_from_torch_geo_with_colors(transformed_mesh, local_preds)\n",
    "            tri_mesh.export(save_path)\n",
    "            np.save(preds_save_path, local_preds.cpu().detach().numpy())\n",
    "\n",
    "            lifts.append(loss.detach().cpu().numpy())\n",
    "            lr_plot.append(cur_rl)\n",
    "            \n",
    "            np.save(os.path.join(save_to_dir, \"loss_plot.npy\"), lifts)\n",
    "            np.save(os.path.join(save_to_dir, \"lr_plot.npy\"), lr_plot)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Paused\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize_shape_as_pierre_furrier(model, MESH_TO_OPTIMIZE, verbose=1, \n",
    "#                                  save_to_dir='Expirements/OptimizationPaper/FurrierDragDiff', lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSDF Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method4_to_arbitatry_loss(points, ply_mesh, model, constraint_rad=0.1, axis=0):\n",
    "\n",
    "    initial_dir = points.grad.clone()\n",
    "    points.grad.data.zero_()\n",
    "\n",
    "    mesh = make_mesh_from_points(points, ply_mesh)\n",
    "    #signs = compute_signs_for_loss(mesh, transformPoints(normals, AvgTransform))\n",
    "    local_preds = model(mesh)\n",
    "    loss = calculate_loss(mesh, local_preds, axis=axis, constraint_rad=constraint_rad)\n",
    "    loss.backward()\n",
    "\n",
    "    sign = [-p1.dot(p2) for p1, p2 in zip(initial_dir, points.grad)]\n",
    "    \n",
    "    return sign, loss, local_preds, mesh\n",
    "\n",
    "def optimize_shape_deepSDF(decoder, latent, ref_latent, initial_points=None, num_points=None, \n",
    "                   num_iters=100, point_iters=100,  punch_lr_at_reindex_by=1, num_neignours_constr=10,\n",
    "                   reindex_latent_each=50, reindex_num_iterations=500, reindex_num_samples=100,\n",
    "                   lr=0.2, decreased_by=2, adjust_lr_every=10, alpha_penalty=0.05,\n",
    "                   multiplier_func=method4_to_arbitatry_loss, verbose=None, save_to_dir=None, N=256):\n",
    "\n",
    "    def adjust_learning_rate(\n",
    "        initial_lr, optimizer, num_iterations, decreased_by, adjust_lr_every\n",
    "    ):\n",
    "        lr = initial_lr * ((1 / decreased_by) ** (num_iterations // adjust_lr_every)) \\\n",
    "                        * ((punch_lr_at_reindex_by) ** (num_iterations // reindex_latent_each))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "            \n",
    "        return lr\n",
    "    \n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'meshes')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'meshes'))\n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'predictions')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'predictions'))\n",
    "\n",
    "\n",
    "    decoder.eval()\n",
    "    latent = latent.clone()\n",
    "    latent.requires_grad = True\n",
    "    optimizer = torch.optim.SGD([latent], lr=lr)\n",
    "\n",
    "    loss_plot = []\n",
    "    latent_dist = []\n",
    "    lr_plot = []\n",
    "\n",
    "    if initial_points is not None:\n",
    "        points = initial_points.clone()\n",
    "    else:\n",
    "        points = get_points_from_latent(decoder, latent, N=N, point_num=num_points)\n",
    "\n",
    "    for i in range(num_iters):\n",
    "\n",
    "        time_start = time.time()\n",
    "\n",
    "        save_path = os.path.join(save_to_dir, 'meshes/' + str(i).zfill(5) + \".ply\")\n",
    "        preds_save_path = os.path.join(save_to_dir, 'predictions/' + str(i).zfill(5) + \".npy\")\n",
    "\n",
    "#             if i > 0 and i == reindex_latent_each:\n",
    "#                 new_latent = get_latent_from_mesh(decoder, latent_size=latent.size()[1], \n",
    "#                                                   num_iterations=reindex_num_iterations, \n",
    "#                                                   num_samples=reindex_num_samples)\n",
    "#                 latent = torch.Tensor(new_latent.cpu().detach().numpy()).cuda()\n",
    "#                 latent.requires_grad = True\n",
    "#                 optimizer = torch.optim.Adam([latent], lr=lr)\n",
    "\n",
    "        cur_rl = adjust_learning_rate(lr, optimizer, i, decreased_by, adjust_lr_every)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ply_mesh = create_mesh( decoder,\n",
    "                                    latent,\n",
    "                                    N=N,\n",
    "                                    max_batch=int(2 ** 18),\n",
    "                                    offset=None,\n",
    "                                    scale=None)\n",
    "\n",
    "        points = torch.cuda.FloatTensor(np.hstack(( ply_mesh['vertex']['x'][:, None], \n",
    "                                                    ply_mesh['vertex']['y'][:, None], \n",
    "                                                    ply_mesh['vertex']['z'][:, None])))\n",
    "\n",
    "\n",
    "        #points = get_points_from_latent(decoder, latent, N=128, point_num=num_points, save_path=save_path) # grid\n",
    "        #points = get_points_on_surface(decoder, latent, points, num_iters=point_iters)  # optimization\n",
    "        points.requires_grad = True\n",
    "\n",
    "        sdf_value = deep_sdf.utils.decode_sdf(decoder, latent, points)\n",
    "        sdf_value.backward(torch.ones([len(points), 1], dtype=torch.float32).cuda())\n",
    "\n",
    "        mults, loss_value, preds, transformed_mesh = multiplier_func(points, ply_mesh)         \n",
    "        multipliers = torch.cuda.FloatTensor(mults)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        sdf_value = torch.squeeze(deep_sdf.utils.decode_sdf(decoder, latent, points))\n",
    "\n",
    "        final_loss = torch.sum(sdf_value * multipliers)\n",
    "        final_loss.backward()\n",
    "#             print( \"Latent size: \", torch.sum(latent ** 2) )\n",
    "#             print( \"Latent grad: \", torch.sum(latent.grad ** 2) )\n",
    "\n",
    "#           sdf_value.backward(multipliers)\n",
    "\n",
    "\n",
    "        # Soft-constraints\n",
    "        distances, indeces = LATENT_KD_TREE.query(latent.cpu().detach(), k=num_neignours_constr)\n",
    "        penalty = torch.mean(\n",
    "                    torch.stack([torch.sum( \n",
    "                                    (latent - latent_vectors[indeces[0][i]]) ** 2\n",
    "                                 )\n",
    "                                 for i in range(len(indeces[0]))]\n",
    "                               )\n",
    "                    )\n",
    "        apenalty = penalty * alpha_penalty\n",
    "        apenalty.backward()\n",
    "        #print(\"Latent grad penalized: \", torch.sum(latent.grad ** 2))\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Hard-constraints\n",
    "#             if (torch.sum(latent ** 2) > 1.2):\n",
    "#                 latent *= 1.2 / torch.sum(latent ** 2)\n",
    "\n",
    "#             loss_value, preds = loss_func(points, ply_mesh)            \n",
    "\n",
    "        tri_mesh = get_trimesh_from_torch_geo_with_colors(transformed_mesh, preds)\n",
    "        tri_mesh.export(save_path)\n",
    "        np.save(preds_save_path, preds.cpu().detach().numpy())\n",
    "\n",
    "        if save_to_dir is not None:\n",
    "            plot_points_from_torch\n",
    "\n",
    "        loss_plot.append(loss_value.cpu().detach().numpy())\n",
    "        latent_dist.append(torch.sum((latent - ref_latent) ** 2 ).cpu().detach().numpy() )\n",
    "        lr_plot.append(penalty)\n",
    "\n",
    "        time_end = time.time()\n",
    "\n",
    "        if verbose is not None and i % verbose == 0:\n",
    "            print('Iter ', i, 'Loss: ', loss_value.detach().cpu().numpy(), ' LD: ', lr_plot[-1])\n",
    "            #plot_points_from_torch(points)\n",
    "#                 print(\"Time: \", time_end - time_start)\n",
    "\n",
    "        np.save(os.path.join(save_to_dir, \"loss_plot.npy\"), loss_plot)\n",
    "        np.save(os.path.join(save_to_dir, \"latent_dist.npy\"), latent_dist)\n",
    "        np.save(os.path.join(save_to_dir, \"lr_plot.npy\"), lr_plot)\n",
    "\n",
    "\n",
    "def make_full_transformation(initial_latent, ref_latent, experiment_name, \n",
    "                             decoder, model, alpha_penalty=0.05, constraint_rad=0.1, axis=0, **kwargs):\n",
    "    '''\n",
    "    kwargs:\n",
    "        num_iters=1000, \n",
    "        adjust_lr_every=10, \n",
    "        decreased_by=1.2,\n",
    "        lr=0.005,\n",
    "        \n",
    "        reindex_latent_each=100,\n",
    "        punch_lr_at_reindex_by=1,\n",
    "        reindex_num_iterations=500, \n",
    "        reindex_num_samples=100,\n",
    "        \n",
    "        verbose=10,\n",
    "    '''\n",
    "\n",
    "    #ref_points = get_points_from_latent(decoder, ref_latent, N=128)\n",
    "\n",
    "    save_to_dir = experiment_name\n",
    "    if not os.path.exists(save_to_dir):\n",
    "        os.makedirs(save_to_dir)\n",
    "\n",
    "    #np.save(os.path.join(save_to_dir, \"target_verts.npy\"), ref_points)\n",
    "\n",
    "    optimize_shape_deepSDF(decoder, initial_latent, ref_latent, initial_points=None,\n",
    "                                           alpha_penalty=alpha_penalty,\n",
    "                                           num_points=None, point_iters=2,\n",
    "                                           multiplier_func=lambda x, y: \n",
    "                                               method4_to_arbitatry_loss(x, y, model, \n",
    "                                                                         constraint_rad=constraint_rad, \n",
    "                                                                         axis=axis),\n",
    "                                           save_to_dir=save_to_dir, **kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Paused\n",
      "Paused\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f486e6543bc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m                          \u001b[0mpunch_lr_at_reindex_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                          \u001b[0mreindex_num_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                          reindex_num_samples=100)\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# FreeFormFurrier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-5e04fef24304>\u001b[0m in \u001b[0;36mmake_full_transformation\u001b[0;34m(initial_latent, ref_latent, experiment_name, decoder, model, alpha_penalty, constraint_rad, axis, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m                                                                          \u001b[0mconstraint_rad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint_rad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                                                                          axis=axis),\n\u001b[0;32m--> 179\u001b[0;31m                                            save_to_dir=save_to_dir, **kwargs)\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-5e04fef24304>\u001b[0m in \u001b[0;36moptimize_shape_deepSDF\u001b[0;34m(decoder, latent, ref_latent, initial_points, num_points, num_iters, point_iters, punch_lr_at_reindex_by, num_neignours_constr, reindex_latent_each, reindex_num_iterations, reindex_num_samples, lr, decreased_by, adjust_lr_every, alpha_penalty, multiplier_func, verbose, save_to_dir, N)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_points_from_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvlabdata2/home/artem/DeepSDF/custom_utils.py\u001b[0m in \u001b[0;36mget_points_from_latent\u001b[0;34m(decoder, initial_latent, N, point_num, save_path)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_points_from_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0mcloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cloud_from_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m     \u001b[0mnparr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpoint_num\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvlabdata2/home/artem/DeepSDF/custom_utils.py\u001b[0m in \u001b[0;36mget_cloud_from_latent\u001b[0;34m(decoder, initial_latent, N, save_path)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                 \u001b[0mmax_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                 \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                 scale=None)\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvlabdata2/home/artem/DeepSDF/custom_utils.py\u001b[0m in \u001b[0;36mcreate_mesh\u001b[0;34m(decoder, latent_vec, filename, N, max_batch, offset, scale)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# to be the x, y, z index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverall_index\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moverall_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverall_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiment_dir = 'FairLossOld'\n",
    "num_iters = 30\n",
    "N = 256\n",
    "\n",
    "nice_shapes = [20, 16, 15, 19, 22]\n",
    "\n",
    "for i in nice_shapes + list(range(30, 100)):\n",
    "    LATENT_TO_OPTIMIZE = latent_vectors[i]\n",
    "    LATENT_KD_TREE = KDTree(np.array([lv.cpu().detach().numpy()[0] for lv in latent_vectors]))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ply_mesh = create_mesh( decoder,\n",
    "                                LATENT_TO_OPTIMIZE,\n",
    "                                N=N,\n",
    "                                max_batch=int(2 ** 18),\n",
    "                                offset=None,\n",
    "                                scale=None)\n",
    "\n",
    "    points = torch.cuda.FloatTensor(np.hstack(( ply_mesh['vertex']['x'][:, None], \n",
    "                                            ply_mesh['vertex']['y'][:, None], \n",
    "                                            ply_mesh['vertex']['z'][:, None])))\n",
    "    normals = torch.cuda.FloatTensor(np.hstack(( ply_mesh['normals']['x'][:, None], \n",
    "                                                 ply_mesh['normals']['y'][:, None], \n",
    "                                                 ply_mesh['normals']['z'][:, None])))\n",
    "\n",
    "    MESH_TO_OPTIMIZE = make_mesh_from_points(points, ply_mesh)\n",
    "    #SAVED_SIGNS = compute_signs_for_loss(MESH_TO_OPTIMIZE, transformPoints(normals, AvgTransform))\n",
    "    \n",
    "    print(\"Starting\")\n",
    "    \n",
    "    for a, name in zip([1, 0.5], ['Down', 'Mix']):\n",
    "        # DeepSDF\n",
    "        mesh = make_full_transformation(LATENT_TO_OPTIMIZE.detach(), LATENT_TO_OPTIMIZE.clone(), \n",
    "                                    'Expirements/OptimizationPaper/' + experiment_dir + \n",
    "                                         '/DeepSDF' + name + '/' + str(i), decoder, model,\n",
    "                         alpha_penalty=0.2, axis=a,\n",
    "                         num_iters=num_iters,\n",
    "                         adjust_lr_every=20,\n",
    "                         decreased_by=1.1, \n",
    "                         lr=0.2,\n",
    "                         verbose=None,\n",
    "                         N=N,\n",
    "                         num_neignours_constr=10,\n",
    "                         reindex_latent_each=10000,\n",
    "                         punch_lr_at_reindex_by=1,\n",
    "                         reindex_num_iterations=500,\n",
    "                         reindex_num_samples=100)\n",
    "\n",
    "        # FreeFormFurrier\n",
    "        optimize_shape_as_pierre_furrier(model, MESH_TO_OPTIMIZE, verbose=None, \n",
    "                                         constraint_rad=0.1, num_iters=num_iters,\n",
    "                                 save_to_dir='Expirements/OptimizationPaper/' + experiment_dir + \n",
    "                                             '/FreeformFurrie' + name + '/' + str(i), \n",
    "                                 lr=0.005, adjust_lr_every=20, axis=a)\n",
    "\n",
    "        # FreeForm\n",
    "        optimize_shape_as_pierre(model, MESH_TO_OPTIMIZE, verbose=None, constraint_rad=0.1, num_iters=num_iters,\n",
    "                                 save_to_dir='Expirements/OptimizationPaper/' + experiment_dir + \n",
    "                                             '/Freeform' + name + '/' + str(i), \n",
    "                                 lr=0.05, adjust_lr_every=20, axis=a)\n",
    "\n",
    "        # Scaling\n",
    "        optimize_shape_by_scaling(model, MESH_TO_OPTIMIZE, verbose=None, constraint_rad=0.1, num_iters=num_iters,\n",
    "                                 save_to_dir='Expirements/OptimizationPaper/' + experiment_dir + \n",
    "                                             '/Scaling' + name + '/' + str(i), \n",
    "                                 lr=0.5, adjust_lr_every=20, axis=a)\n",
    "\n",
    "#       Vertex\n",
    "        optimize_shape_by_vertex(model, MESH_TO_OPTIMIZE, verbose=None, constraint_rad=0.1, num_iters=num_iters,\n",
    "                                 save_to_dir='Expirements/OptimizationPaper/' + experiment_dir + \n",
    "                                             '/Vertex' + name + '/' + str(i), \n",
    "                                 lr=0.05, adjust_lr_every=20, axis=a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "my_data = genfromtxt('../Expirements/SavedTransforms/DeepSDF-CFD8-m3-holes/report/00000/output/cloud_p_k_omega_nut.csv', \n",
    "                     delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = trimesh.load(\"../Data/cars_remeshed_dsdf/inputs/0_input.stl\")\n",
    "norm = mpl.colors.Normalize(vmin= -2, vmax=2)\n",
    "cmap = cm.hot\n",
    "m = cm.ScalarMappable(norm=norm, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fld_tree = KDTree(my_data[:, :3])\n",
    "distances, indeces = fld_tree.query(mesh.vertices, k=1)\n",
    "\n",
    "interpolations = my_data[:, 0][indeces].squeeze()\n",
    "mesh = trimesh.Trimesh(vertices=mesh.vertices, faces=mesh.faces, \n",
    "                           vertex_colors=list(map(lambda c: m.to_rgba(c),  interpolations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = trimesh.load(\"../Data/cars_refined/simulated/stl/0005.stl\")\n",
    "mesh.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = make_data_instance_from_stl(\"/cvlabdata2/home/artem/Data/check_simulations/Processed/fld/0002_0005.fld\")\n",
    "di.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = get_trimesh_from_torch_geo_with_colors(di, di.y)\n",
    "lift = compute_lift_faces(di, di.y)\n",
    "print('Lift: ', lift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(di.y[:, 0].detach().cpu().numpy(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npar = np.genfromtxt(\"/cvlabdata2/home/artem/Data/check_simulations/Processed/fld/0002_0005.fld\", delimiter=',', skip_header=1)\n",
    "plt.hist(npar[:, 3], bins=100, alpha = 0.5)\n",
    "npar = np.genfromtxt(\"/cvlabdata2/home/artem/Data/check_simulations/Processed/fld/0000_0005.fld\", delimiter=',', skip_header=1)\n",
    "plt.hist(npar[:, 3], bins=100, alpha = 0.5)\n",
    "npar = np.genfromtxt(\"/cvlabdata2/home/artem/Data/check_simulations/Processed/fld/0001_0005.fld\", delimiter=',', skip_header=1)\n",
    "plt.hist(npar[:, 3], bins=100, alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npar = np.genfromtxt(\"/cvlabdata2/home/artem/Data/cars_refined/simulated/fld/0002_0005.fld\", delimiter=',', skip_header=1)\n",
    "plt.hist(npar[:, 3], bins=100, alpha = 0.5)\n",
    "npar = np.genfromtxt(\"/cvlabdata2/home/artem/Data/cars_refined/simulated/fld/0003_0005.fld\", delimiter=',', skip_header=1)\n",
    "plt.hist(npar[:, 3], bins=100, alpha = 0.5)\n",
    "npar = np.genfromtxt(\"/cvlabdata2/home/artem/Data/cars_refined/simulated/fld/0007_0005.fld\", delimiter=',', skip_header=1)\n",
    "plt.hist(npar[:, 3], bins=100, alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npar = np.genfromtxt(\"/cvlabdata2/home/artem/Data/check_simulations/ListenerCheck/processed/fld/0000_0005.fld\", delimiter=',', skip_header=1)\n",
    "plt.hist(npar[:, 3], bins=100, alpha = 0.5)\n",
    "npar = np.genfromtxt(\"/cvlabdata2/home/artem/Data/check_simulations/ListenerCheck/processed/fld/0001_0005.fld\", delimiter=',', skip_header=1)\n",
    "plt.hist(npar[:, 3], bins=100, alpha = 0.5)\n",
    "npar = np.genfromtxt(\"/cvlabdata2/home/artem/Data/check_simulations/ListenerCheck/processed/fld/0002_0005.fld\", delimiter=',', skip_header=1)\n",
    "plt.hist(npar[:, 3], bins=100, alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di0 = make_data_instance_from_stl(\"../Expirements/SimulatedResults/foam_npy/fld/0000_0005.fld\")\n",
    "di1 = make_data_instance_from_stl(\"../Expirements/SimulatedResults/foam_npy/fld/0001_0005.fld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(di0.y[:, 0], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(di1.y[:, 0], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = trimesh.load('/cvlabdata2/home/artem/Data/cars_refined/simulated/stl/0005.stl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Expirements/SavedTransforms/DeepSDF-CFD8-m3-holes/meshes/00000.ply'\n",
    "tri_mesh = trimesh.load(path)\n",
    "points = torch.tensor(tri_mesh.vertices, dtype=torch.float).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innerBoundsLoss(points, r=0.12**2, center=(0.55, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "bvecs = genfromtxt('examples/cars/vine_latentVecs_tll_0.1_1.csv', delimiter=' ', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bvecs = [torch.FloatTensor(v).to('cuda:0') for v in bvecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ply_mesh = create_mesh( decoder,\n",
    "                        latent_vectors[0],\n",
    "                        N=128,\n",
    "                        max_batch=int(2 ** 18),\n",
    "                        offset=None,\n",
    "                        scale=None)\n",
    "\n",
    "points = torch.cuda.FloatTensor(\n",
    "    np.array([ply_mesh['vertex']['x'], ply_mesh['vertex']['y'], ply_mesh['vertex']['z']]).transpose()\n",
    ")\n",
    "\n",
    "transformed_points = make_mesh_from_points(points, ply_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(transformed_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = get_trimesh_from_torch_geo_with_colors(transformed_points, pred.cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = mesh.export('examples/cars/BeautifiedMeshes/o0.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_latent_from_mesh_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = trimesh.geometry.faces_to_edges(ply_mesh['face']['vertex_indices'])\n",
    "edge_attr = torch.stack([points[a] - points[b] for a, b in edges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_attr[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = PyntCloud(pd.DataFrame(points.cpu().detach().numpy(), columns=['x', 'y', 'z']))\n",
    "cloud.plot(background='white', initial_point_size=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = PyntCloud(pd.DataFrame(points_transformed.cpu().detach().numpy(), columns=['x', 'y', 'z']))\n",
    "cloud.plot(background='white', initial_point_size=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = make_data_instance_from_stl('/cvlabdata2/home/artem/Data/cars_refined/simulated/fld/0007_0005.fld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = get_trimesh_from_torch_geo_with_colors(di, di.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = PyntCloud(pd.DataFrame(di.pos.cpu().detach().numpy(), columns=['x', 'y', 'z']))\n",
    "cloud.plot(background='white', initial_point_size=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = PyntCloud(pd.DataFrame(transformed_points.pos.cpu().detach().numpy(), columns=['x', 'y', 'z']))\n",
    "cloud.plot(background='white', initial_point_size=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ply_mesh = create_mesh( decoder,\n",
    "                            latent,\n",
    "                            N=128,\n",
    "                            max_batch=int(2 ** 18),\n",
    "                            offset=None,\n",
    "                            scale=None)\n",
    "\n",
    "points = torch.cuda.FloatTensor(np.hstack(( ply_mesh['vertex']['x'][:, None], \n",
    "                                            ply_mesh['vertex']['y'][:, None], \n",
    "                                            ply_mesh['vertex']['z'][:, None])))\n",
    "\n",
    "mesh = trimesh.Trimesh(vertices=points.cpu().detach(), faces=ply_mesh['face']['vertex_indices'])\n",
    "edge_attr = [mesh.vertices[a] - mesh.vertices[b] for a, b in mesh.edges]\n",
    "\n",
    "data = torch_geometric.data.Data(x  = points, \n",
    "                                 pos= torch.tensor(mesh.vertices, dtype=torch.float).to('cuda:0'), \n",
    "                                 faces = torch.tensor(mesh.faces, dtype=torch.long).to('cuda:0'),\n",
    "                                 edge_attr = torch.tensor(edge_attr, dtype=torch.float).to('cuda:0'),\n",
    "                                 edge_index= torch.tensor(mesh.edges, dtype=torch.long).t().contiguous().to('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_instance= make_data_instance_from_stl(\n",
    "                    '/cvlabsrc1/cvlab/dataset_shapenet/code/foam_npy/fld/0100_0005.fld', data_step=1)\n",
    "mesh = trimesh.Trimesh(vertices=data_instance.pos, faces=data_instance.faces)\n",
    "a = mesh.export('../Expirements/data/original_mesh.ply')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expirements with PreprocessMesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = get_latent_from_mesh_cpu(decoder, latent_size, mesh, num_iterations=300, num_samples=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_gpu = get_latent_from_mesh(decoder, latent_size, mesh_path='../Expirements/data/original_mesh.ply', \n",
    "                         num_iterations=300, num_samples=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_points = deep_sdf.data.read_sdf_samples_into_ram('../Expirements/data/original_SDF.npz')\n",
    "gpu_points[1][:, 3].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = PyntCloud(pd.DataFrame(np.array(gpu_points[0][:, :3]), columns=['x', 'y', 'z']))\n",
    "cloud.plot(background='white', initial_point_size=0.03, elev=-45, azim=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points, sdf = sample_sdf_near_surface(mesh)\n",
    "sdfs = np.hstack((points, sdf[:, None]))\n",
    "data_sdf = [torch.from_numpy(sdfs[sdfs[:, 3] > 0, :]), \n",
    "            torch.from_numpy(sdfs[sdfs[:, 3] < 0, :])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_sdf[0].shape)\n",
    "print(gpu_points[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = PyntCloud(pd.DataFrame(np.array(data_sdf[0][:, :3]), columns=['x', 'y', 'z']))\n",
    "cloud.plot(background='white', initial_point_size=0.03, elev=-45, azim=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh_from_vector(decoder, latent, N=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plydata = create_mesh(decoder, latent_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plydata.write(\"../Expirements/mesh.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
